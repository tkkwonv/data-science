{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모형 평가\n",
    "분류 분석 모형의 평가는 예측 및 분류를 위해 구축된 모형이 임의의 모형보다 더 우수한 분류 성과를 보이는지와 고려된 서로 다른 모형들 중 어느것이 가장 우수한 예측 및 분류 성과를 보유하고 있는지 등을 비교 분석하는 과정이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모형평가 기준\n",
    "\n",
    "### 일반화의 가능성\n",
    "같은 모집단 내의 다른 데이터에 적용하는 경우에도 안정적인 결과를 제공하는 것을 의미하며 데이터를 확장하며 데이터를 확장하여 적용할 수 있는지에 대한 평가 기준이다.\n",
    "\n",
    "### 효율성\n",
    "분류 분석 모형이 얼마나 효과적으로 구축되었는지 평가하게 되며 적은 입력변수를 필요로 할수록 효율성이 높다고 할 수 있다.\n",
    "\n",
    "### 예측과 분류의 정확성\n",
    "구축된 모형의 정확성 측면에서 평가하는 것으로 안정적이고 효율적인 모형을 구축하였다 하더라도 실제 문제에 적용했을 때 정확하지 못한 결과만을 양산한다면 그 모형은 의미를 가질 수 없다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 검증용 자료 추출\n",
    "분류 분석 모형의 평가를 위해서 먼저 전체 자료에서 모형 구축을 위한 훈련용 자료와 모형의 성과를 검증하기 위한 검증용 자료를 추출한다.\n",
    "\n",
    "### 홀드아웃 방법(Holdout method)\n",
    "일반적으로 전체 데이터 중 70%의 데이터는 훈련용 자료로 사용하고 나머지는 검증용 자료로 사용한다.\n",
    "\n",
    "### 교차검증(cross-validation)\n",
    "주어진 데이터를 가지고 반복적으로 성과를 측정하여 그 결과를 평균한 것으로 분류 분석 모형을 평가하는 방법이다.\n",
    "\n",
    "### 붓스트랩(bootstrap)\n",
    "평가를 반복하는 측면에서 교차검증과 유사하나 훈련용 자료를 반복 재선정한다는 점에서 차이가 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 오분류표(Confusion matrix)\n",
    "대부분의 분류 분석 모형의 예측 결과는 분류 범주로 나타남에 따라 분류 분석 모형의 평가에는 Confusion matrix가 일반적으로 사용된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 정분류율(accuracy, recognition rate)\n",
    "전체 관측치중 실제값과 예측치가 일치한 정도를 나타낸다.\n",
    "\n",
    "accuracy = (TP+TN)/(P+N)\n",
    "\n",
    "## 민감도(sensitivity) \n",
    "실제값이 True인 관측치 중 예측치가 적중한 정도를 나타낸다.\n",
    "\n",
    "sensitivity = TP/P\n",
    "\n",
    "## 특이도(specificity)\n",
    "실제값이 False인 관측치 중 예측치가 적중한 정도를 나타낸다.\n",
    "\n",
    "specificity = TN/N\n",
    "\n",
    "## 정확도(precision)\n",
    "True로 예측한 관측치 중 실제값이 True인 정도를 나타내는 정확성(exactness) 지표이다.\n",
    "\n",
    "Precision = TP/(TP+FP)\n",
    "\n",
    "## 재현율(recall)\n",
    "실제값이 True인 관측치 중 예측치가 적중한 정도를 나타내는 민감도와 동일한 지표로 모형의 완전성(completeness)을 평가하는 지표이다.\n",
    "\n",
    "Recall = TP/(TP+FN) = TP/P\n",
    "\n",
    "## F1지표(F1 score)\n",
    "정확도와 재현율은 모형의 평가에 대표적으로 사용되는 지표이긴 하지만 한 지표의 값이 높아지면 다른 지표의 값이 낮아질 가능성이 높은 관계를 지니고 있다. 예를 들어 암환자의 분류 분석 모형에서 대부분의 사람을 암환자로 예측하였다고 가정하면 높은 정확도를 가지게 되지만 재편율은 현저히 낮은 값을 보이게 된다. 따라서 이러한 효과를 보정하여 하나의 지표로 나타낸 것이 F1지표(F1 score)이다.\n",
    "\n",
    "F1 = 1*Precision*Recall/(Precision+Recall)\n",
    "\n",
    "F1지표는 정확도와 재현율의 조화평균을 나타내며 정확도와 재현율에 같은 가중치를 부여하여 평균하게 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [예제]\n",
    "iris 자료에 대해 범주가 2개인 분류 모형을 구축하기 위해 iris 자료의 일부분만 이용하기로 한다.  \n",
    "Species가 setosa와 versicolor인 100개의 자료만을 이용하여 70%의 훈련용 자료를 추출한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "70"
      ],
      "text/latex": [
       "70"
      ],
      "text/markdown": [
       "70"
      ],
      "text/plain": [
       "[1] 70"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "iris <- subset(iris, Species == \"setosa\" | Species == \"versicolor\")\n",
    "iris$Species <- factor(iris$Species)\n",
    "set.seed(1234)\n",
    "iris <- iris[sample(nrow(iris)),] #Randomly shuffle the data\n",
    "trainData <- iris[1:(nrow(iris)*0.7),]\n",
    "testData <- iris[((nrow(iris)*0.7)+1):nrow(iris),]\n",
    "nrow(trainData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "훈련용 자료를 사용하여 각 모형을 학습한다.  \n",
    "신경망 모형은 R패키지{nnet}의 nnet() 함수를 이용하며 의사결정나무 모형은 {rpart}의 rpart() 함수를 이용하여 모형을 학습한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# weights:  13\n",
      "initial  value 48.493030 \n",
      "iter  10 value 0.463588\n",
      "iter  20 value 0.365093\n",
      "iter  30 value 0.240507\n",
      "iter  40 value 0.215235\n",
      "iter  50 value 0.169086\n",
      "iter  60 value 0.113028\n",
      "iter  70 value 0.103250\n",
      "iter  80 value 0.102977\n",
      "iter  90 value 0.102736\n",
      "iter 100 value 0.102655\n",
      "iter 110 value 0.102567\n",
      "iter 120 value 0.102543\n",
      "iter 130 value 0.102539\n",
      "iter 140 value 0.102537\n",
      "iter 150 value 0.102536\n",
      "iter 160 value 0.102535\n",
      "final  value 0.102535 \n",
      "converged\n"
     ]
    }
   ],
   "source": [
    "library(nnet)\n",
    "library(rpart)\n",
    "nn.iris <- nnet(Species~., data=trainData, size=2, rang=0.1, decay=5e-4, maxit=200) # Neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.iris <- rpart(Species~., data=trainData) # Decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "다음은 학습된 각 분류 분석 모형을 검증용 자료에 적용시켜 예측값을 도출한다.  \n",
    "이를 위하여 predict() 함수를 사용한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_pred <- predict(nn.iris, testData, type=\"class\")\n",
    "dt_pred <- predict(dt.iris, testData, type=\"class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "각 모형의 오분류표를 도출하기 위하여 R 패키지 {caret}의 confusionMatrix() 함수를 이용한다.   \n",
    "R 패키지 {e1071} 설치 필요"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error: `data` and `reference` should be factors with the same levels.\n",
     "output_type": "error",
     "traceback": [
      "Error: `data` and `reference` should be factors with the same levels.\nTraceback:\n",
      "1. confusionMatrix(nn_pred, testData$Species)",
      "2. confusionMatrix.default(nn_pred, testData$Species)",
      "3. stop(\"`data` and `reference` should be factors with the same levels.\", \n .     call. = FALSE)"
     ]
    }
   ],
   "source": [
    "library(caret)\n",
    "nn_con=confusionMatrix(nn_pred, testData$Species)\n",
    "dt_con=confusionMatrix(dt_pred, testData$Species)\n",
    "nn_con$table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
